{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv.zip' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that very low values are used to signal unavailable data\n",
    "tX[tX < -900] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import sample_data, standardize\n",
    "seed = 1\n",
    "\n",
    "tX_mean = np.nanmean(tX,axis=0)\n",
    "\n",
    "tX_std = np.nanstd(tX,axis=0)\n",
    "norm_tX = np.subtract(tX, tX_mean, where=np.isfinite(tX_mean))\n",
    "norm_tX = np.divide(norm_tX, tX_std, where=tX_std>0)\n",
    "norm_tX[np.isnan(norm_tX)] =0\n",
    "#norm_tX = np.c_[np.ones(num_samples), norm_tX]\n",
    "\n",
    "#y, norm_tX = sample_data(y, norm_tX, seed, len(y[0]))#size_samples= 100000)\n",
    "norm_tX, mean_x, std_x = standardize(norm_tX)\n",
    "\n",
    "norm_tX = np.c_[np.ones((y.shape[0], 1)), norm_tX]\n",
    "initial_w = np.zeros((norm_tX.shape[1], 1))\n",
    "\n",
    "\n",
    "#print(initial_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 31)\n",
      "(31, 1)\n",
      "Current iteration=0, loss=173286.79513997526, gamma=9e-08\n",
      "Current iteration=100, loss=12086.40984498414, gamma=1e-09\n",
      "Current iteration=200, loss=8052.144342288651, gamma=1e-09\n",
      "Current iteration=300, loss=5496.583422731463, gamma=5e-10\n",
      "Current iteration=400, loss=3514.0307696425443, gamma=5e-10\n",
      "Current iteration=500, loss=1543.5061312556354, gamma=5e-10\n",
      "Current iteration=600, loss=695.9132725131931, gamma=1e-10\n",
      "Current iteration=700, loss=304.2555216173496, gamma=1e-10\n",
      "Current iteration=800, loss=74.9618041679496, gamma=1e-11\n",
      "Current iteration=900, loss=36.20130909176078, gamma=9e-12\n",
      "loss=1.0040284043061547\n"
     ]
    }
   ],
   "source": [
    "from Implementation import logistic_regression_gd\n",
    "\n",
    "# init parameters\n",
    "max_iter = 1000\n",
    "gamma = 0.00000009\n",
    "initial_w = np.zeros((norm_tX.shape[1], 1))\n",
    "\n",
    "print(np.shape(y))\n",
    "print(np.shape(norm_tX))\n",
    "print(np.shape(initial_w))\n",
    "\n",
    "    \n",
    "weights = logistic_regression_gd(y, norm_tX, initial_w, max_iter, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=173286.79513997526\n",
      "Current iteration=100, loss=139532.81780052732\n",
      "Current iteration=200, loss=109541.44047085172\n",
      "Current iteration=300, loss=82519.39359495089\n",
      "Current iteration=400, loss=57869.8509180984\n",
      "Current iteration=500, loss=35145.79231381694\n",
      "Current iteration=600, loss=18619.654770215184\n",
      "Current iteration=700, loss=14499.590184916917\n",
      "Current iteration=800, loss=10432.522224648568\n",
      "Current iteration=900, loss=6676.164901606581\n",
      "Current iteration=1000, loss=4685.322930473504\n",
      "Current iteration=1100, loss=2706.6686377977453\n",
      "Current iteration=1200, loss=928.2854446174633\n",
      "Current iteration=1300, loss=536.1508126432315\n",
      "Current iteration=1400, loss=144.48679264322004\n",
      "Current iteration=1500, loss=59.55778142781853\n",
      "loss=22.344184180736193\n",
      "[[-6.18875337e-01]\n",
      " [ 7.53280508e-03]\n",
      " [-2.31162685e-01]\n",
      " [-7.36011227e-03]\n",
      " [ 9.97224563e-02]\n",
      " [ 1.09912531e-01]\n",
      " [ 1.01786746e-01]\n",
      " [-9.48998791e-02]\n",
      " [ 3.46695722e-02]\n",
      " [-2.49986449e-02]\n",
      " [ 7.06548804e-02]\n",
      " [-1.27459689e-01]\n",
      " [ 1.65530718e-01]\n",
      " [ 1.06251903e-01]\n",
      " [ 1.44403899e-01]\n",
      " [-8.71255966e-04]\n",
      " [-3.22939837e-03]\n",
      " [-2.30946191e-02]\n",
      " [ 5.60931037e-04]\n",
      " [ 2.89558810e-03]\n",
      " [-4.55185099e-03]\n",
      " [ 4.59451071e-03]\n",
      " [ 5.86878291e-02]\n",
      " [ 6.25180538e-02]\n",
      " [ 3.33386271e-02]\n",
      " [ 1.02786231e-04]\n",
      " [-3.99004155e-05]\n",
      " [-2.44248648e-02]\n",
      " [ 6.32800123e-04]\n",
      " [-2.07747292e-03]\n",
      " [ 5.55869534e-02]]\n"
     ]
    }
   ],
   "source": [
    "from Implementation import regu_logistic_regression_gd\n",
    "\n",
    "# init parameters\n",
    "max_iter = 1600\n",
    "gamma = 0.000000005\n",
    "#gamma = 0.00000009\n",
    "lambda_ = 0.001\n",
    "\n",
    "\n",
    "initial_w = np.zeros((norm_tX.shape[1], 1))\n",
    "\n",
    "\n",
    "weights = regu_logistic_regression_gd(y, norm_tX, lambda_, initial_w, max_iter, gamma )\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares and Polynomial regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = polynomial_regression(norm_tX)\n",
    "#weights = polynomial_regression(norm_tX2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Implementation import compute_mse, calculate_loss\n",
    "\n",
    "def train_test_split_demo(x, y, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\"\"\"\n",
    "    x_tr, x_te, y_tr, y_te = split_data(x, y, ratio, seed)\n",
    "    # form tx\n",
    "    #tx_tr = build_poly(x_tr, degree)\n",
    "    #tx_te = build_poly(x_te, degree)\n",
    "   \n",
    "    tx_tr =x_tr\n",
    "    tx_te = x_te\n",
    "    #tx_tr = np.ones((len(x_tr), 1))\n",
    "    #tx_tr = np.c_[tx_tr, np.power(x_tr, 1)]\n",
    "    #tx_te = np.ones((len(x_te), 1))\n",
    "    #tx_te = np.c_[tx_te, np.power(x_te, 1)]\n",
    "    \n",
    "\n",
    "    # init parameters\n",
    "    max_iter = 1000\n",
    "    gamma = 0.00000009\n",
    "    initial_w = np.zeros((tx_tr.shape[1], 1))\n",
    "    \n",
    "    print(np.shape(y_tr))\n",
    "    print(np.shape(tx_tr))\n",
    "    print(np.shape(initial_w))\n",
    "    \n",
    "\n",
    "\n",
    "    weight = logistic_regression_gd(y_tr, tx_tr, initial_w, max_iter, gamma)\n",
    "    \n",
    "    y_tr = np.expand_dims(y_tr, axis=1)\n",
    "    y_te = np.expand_dims(y_te, axis=1)\n",
    "    \n",
    "    # calculate RMSE for train and test data.\n",
    "    #rmse_tr = np.sqrt(2 * compute_mse(y_tr, tx_tr, weight))\n",
    "    #rmse_te = np.sqrt(2 * compute_mse(y_te, tx_te, weight))\n",
    "    \n",
    "    #calculate cost for train and test data\n",
    "    cost_tr = calculate_loss(y_tr, tx_tr, weight)\n",
    "    cost_te = calculate_loss(y_te, tx_te, weight)\n",
    "\n",
    "    print(\"proportion={p}, logistic reg, Training loss={tr:.3f}, Testing loss={te:.3f}\".format(\n",
    "          p=ratio, tr=cost_tr, te=cost_te))\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000,)\n",
      "(225000, 31)\n",
      "(31, 1)\n",
      "Current iteration=0, loss=155958.115625978, gamma=9e-08\n",
      "Current iteration=100, loss=13585.566861166793, gamma=1e-09\n",
      "Current iteration=200, loss=10297.21756350089, gamma=1e-09\n",
      "Current iteration=300, loss=7046.212538515596, gamma=1e-09\n",
      "Current iteration=400, loss=5386.16481027627, gamma=5e-10\n",
      "Current iteration=500, loss=3783.517129692569, gamma=5e-10\n",
      "Current iteration=600, loss=2189.648736241448, gamma=5e-10\n",
      "Current iteration=700, loss=908.1271077283309, gamma=1e-10\n",
      "Current iteration=800, loss=591.7859049540566, gamma=1e-10\n",
      "Current iteration=900, loss=275.78545912001573, gamma=1e-10\n",
      "loss=82.24524788178678\n",
      "proportion=0.9, logistic reg, Training RMSE=82.245, Testing RMSE=-214.437\n",
      "(175000,)\n",
      "(175000, 31)\n",
      "(31, 1)\n",
      "Current iteration=0, loss=121300.75659798345, gamma=9e-08\n",
      "Current iteration=100, loss=16688.051180456037, gamma=1e-09\n",
      "Current iteration=200, loss=14626.109511646064, gamma=1e-09\n",
      "Current iteration=300, loss=12583.417267372977, gamma=1e-09\n",
      "Current iteration=400, loss=10559.504634133875, gamma=1e-09\n",
      "Current iteration=500, loss=8553.917536586785, gamma=1e-09\n",
      "Current iteration=600, loss=6764.196531788781, gamma=5e-10\n",
      "Current iteration=700, loss=5776.062411556428, gamma=5e-10\n",
      "Current iteration=800, loss=4792.251893560708, gamma=5e-10\n",
      "Current iteration=900, loss=3812.7138996048016, gamma=5e-10\n",
      "loss=2837.3981831783312\n",
      "proportion=0.7, logistic reg, Training RMSE=2837.398, Testing RMSE=1431.180\n",
      "(200000,)\n",
      "(200000, 31)\n",
      "(31, 1)\n",
      "Current iteration=0, loss=138629.43611198076, gamma=9e-08\n",
      "Current iteration=100, loss=15716.179469759052, gamma=1e-09\n",
      "Current iteration=200, loss=13070.49997023432, gamma=1e-09\n",
      "Current iteration=300, loss=10452.291922635544, gamma=1e-09\n",
      "Current iteration=400, loss=7860.803723275458, gamma=1e-09\n",
      "Current iteration=500, loss=6126.298878140602, gamma=5e-10\n",
      "Current iteration=600, loss=4848.997442843378, gamma=5e-10\n",
      "Current iteration=700, loss=3577.9904520111595, gamma=5e-10\n",
      "Current iteration=800, loss=2313.193820634362, gamma=5e-10\n",
      "Current iteration=900, loss=1054.5250107314496, gamma=5e-10\n",
      "loss=743.3162775266828\n",
      "proportion=0.8, logistic reg, Training RMSE=743.316, Testing RMSE=174.078\n",
      "(225000,)\n",
      "(225000, 31)\n",
      "(31, 1)\n",
      "Current iteration=0, loss=155958.115625978, gamma=9e-08\n",
      "Current iteration=100, loss=13585.566861166793, gamma=1e-09\n",
      "Current iteration=200, loss=10297.21756350089, gamma=1e-09\n",
      "Current iteration=300, loss=7046.212538515596, gamma=1e-09\n",
      "Current iteration=400, loss=5386.16481027627, gamma=5e-10\n",
      "Current iteration=500, loss=3783.517129692569, gamma=5e-10\n",
      "Current iteration=600, loss=2189.648736241448, gamma=5e-10\n",
      "Current iteration=700, loss=908.1271077283309, gamma=1e-10\n",
      "Current iteration=800, loss=591.7859049540566, gamma=1e-10\n",
      "Current iteration=900, loss=275.78545912001573, gamma=1e-10\n",
      "loss=82.24524788178678\n",
      "proportion=0.9, logistic reg, Training RMSE=82.245, Testing RMSE=-214.437\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "degrees = [7]\n",
    "#split_ratio = 0.9\n",
    "split_ratios = [0.7, 0.8 , 0.9]\n",
    "weights = train_test_split_demo(norm_tX, y, split_ratio, seed)\n",
    "\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "      weights = train_test_split_demo(norm_tX, y, split_ratio, seed)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv.zip' # TODO: download train data and supply path here \n",
    "y, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that very low values are used to signal unavailable data\n",
    "#tX_test[tX_test < -900] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_mean = np.nanmean(tX_test,axis=0)\n",
    "tX_test_std = np.nanstd(tX_test,axis=0)\n",
    "norm_tX_test = np.subtract(tX_test, tX_test_mean, where=np.isfinite(tX_test_mean))\n",
    "norm_tX_test = np.divide(norm_tX_test, tX_test_std, where=tX_test_std>0)\n",
    "norm_tX_test = np.c_[np.ones((y.shape[0], 1)), norm_tX_test]\n",
    "#norm_tX_test = build_poly(norm_tX_test, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.18875337e-01]\n",
      " [ 7.53280508e-03]\n",
      " [-2.31162685e-01]\n",
      " [-7.36011227e-03]\n",
      " [ 9.97224563e-02]\n",
      " [ 1.09912531e-01]\n",
      " [ 1.01786746e-01]\n",
      " [-9.48998791e-02]\n",
      " [ 3.46695722e-02]\n",
      " [-2.49986449e-02]\n",
      " [ 7.06548804e-02]\n",
      " [-1.27459689e-01]\n",
      " [ 1.65530718e-01]\n",
      " [ 1.06251903e-01]\n",
      " [ 1.44403899e-01]\n",
      " [-8.71255966e-04]\n",
      " [-3.22939837e-03]\n",
      " [-2.30946191e-02]\n",
      " [ 5.60931037e-04]\n",
      " [ 2.89558810e-03]\n",
      " [-4.55185099e-03]\n",
      " [ 4.59451071e-03]\n",
      " [ 5.86878291e-02]\n",
      " [ 6.25180538e-02]\n",
      " [ 3.33386271e-02]\n",
      " [ 1.02786231e-04]\n",
      " [-3.99004155e-05]\n",
      " [-2.44248648e-02]\n",
      " [ 6.32800123e-04]\n",
      " [-2.07747292e-03]\n",
      " [ 5.55869534e-02]]\n",
      "[[-1.6211706 ]\n",
      " [-1.14806572]\n",
      " [-1.1510502 ]\n",
      " ...\n",
      " [-0.68100117]\n",
      " [-0.30220966]\n",
      " [-1.51270127]]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = 'data/sample-submission' # TODO: fill in desired name of output file for submission\n",
    "#print(np.shape(y))\n",
    "#print(np.shape(norm_tX_test))\n",
    "#print(np.shape(weights))\n",
    "print(weights)\n",
    "y_pred = predict_labels(weights, norm_tX_test)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
